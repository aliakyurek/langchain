{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Basics notebook, we created templates and invoked them and finally feed the result to the LLM. We can make this easier by using Langchain expression language which is very similar to the piping in the Linux shells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Iâ€™m an AI language model created by OpenAI. I'm here to assist you with information, answer questions, and engage in conversation. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "out = llm.invoke(\"Hello, who are you?\")\n",
    "print(out.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools can be passed to chat models that support tool calling allowing the model to request the execution of a specific function with specific inputs if it decides to use it. A tool can be a very simple function and also complex functions that can be used to perform complex operations.  \n",
    "`@tool` decorator is used to create tools that can be used in the model call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "   \"\"\"Multiply two numbers.\"\"\"\n",
    "   return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply.name='multiply'\n",
      "multiply.description='Multiply two numbers.'\n",
      "multiply.args={'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{multiply.name=}\")\n",
    "print(f\"{multiply.description=}\")\n",
    "print(f\"{multiply.args=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self test\n",
    "multiply.invoke({'a':2, 'b':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more complex tool can be defined as the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "@tool\n",
    "def get_stock_price(symbol):\n",
    "    \"\"\"Get the latest price of stock 'symbol'\"\"\"\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    todays_data = ticker.history(period='1d')\n",
    "    return float(todays_data.iloc[0]['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238.9062957763672"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stock_price.invoke({'symbol':\"AAPL\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238.9062957763672"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stock_price.invoke(\"AAPL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can bind the tools to the model in three ways:\n",
    "\n",
    "1. In constructor with kwargs\n",
    "2. via invoke\n",
    "3. After construction with bind_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constructor with kwargs (model specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass the tools to the underlying LLM model, but the tool should have exactly the same structure as LLM expects. Therefore we need to wrap the tool using convert_to_openai_tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "openai_tools = [convert_to_openai_tool(get_stock_price)]\n",
    "\n",
    "llm_with_default_tools = ChatOpenAI(model_kwargs={'tools':openai_tools})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lwNilinnaYg06ifa2I1bomew', 'function': {'arguments': '{\"symbol\":\"GOOGLE\"}', 'name': 'get_stock_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 56, 'total_tokens': 73, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d99acb6c-533c-4386-b295-271fa2b22e29-0', tool_calls=[{'name': 'get_stock_price', 'args': {'symbol': 'GOOGLE'}, 'id': 'call_lwNilinnaYg06ifa2I1bomew', 'type': 'tool_call'}], usage_metadata={'input_tokens': 56, 'output_tokens': 17, 'total_tokens': 73, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_default_tools.invoke(\"What is the price of GOOGLE stock?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### via invoke (model specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_h6GAswTpI9ANErcby27vB8PE', 'function': {'arguments': '{\"symbol\":\"GOOGL\"}', 'name': 'get_stock_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 55, 'total_tokens': 73, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ac35ac60-ed99-4f76-aaf0-626fa0209303-0', tool_calls=[{'name': 'get_stock_price', 'args': {'symbol': 'GOOGL'}, 'id': 'call_h6GAswTpI9ANErcby27vB8PE', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 18, 'total_tokens': 73, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is the price of GOOGLE stock?\", tools=openai_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### via langchain bind_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easiest, model independent, and most flexible way is to use bind_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_binded_tools = llm.bind_tools([get_stock_price])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_JF0f5rQTGm1708zMZs1VYvEf', 'function': {'arguments': '{\"symbol\":\"GOOGL\"}', 'name': 'get_stock_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 55, 'total_tokens': 73, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3441d54a-0b71-44e7-8dfa-8ef22d89d157-0', tool_calls=[{'name': 'get_stock_price', 'args': {'symbol': 'GOOGL'}, 'id': 'call_JF0f5rQTGm1708zMZs1VYvEf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 18, 'total_tokens': 73, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = llm_with_binded_tools.invoke(\"What is the price of GOOGLE stock?\")\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen model succesfully returned the hint to call the tool with the correct parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_stock_price',\n",
       "  'args': {'symbol': 'GOOGL'},\n",
       "  'id': 'call_JF0f5rQTGm1708zMZs1VYvEf',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we asked a question that the model doesn't decide to use a tool, the tool_calls will be empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = llm_with_binded_tools.invoke(\"What is wheather in New York?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I currently don't have access to real-time weather data. You can check a reliable weather website or app for the latest weather updates in New York.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 55, 'total_tokens': 86, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-9cef2dc7-698a-4bf5-8c7d-25824fa3bf72-0', usage_metadata={'input_tokens': 55, 'output_tokens': 31, 'total_tokens': 86, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tool calling is not useful without executing the tool. Simply the args in the result of tool_calls of model response can be passed to the tool to get the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_2S9hafQXn8fKsTBRedVyaTrb', 'function': {'arguments': '{\"symbol\":\"GOOGL\"}', 'name': 'get_stock_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 55, 'total_tokens': 73, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a3b19e12-49a5-4701-b5d8-e228b050cb1e-0', tool_calls=[{'name': 'get_stock_price', 'args': {'symbol': 'GOOGL'}, 'id': 'call_2S9hafQXn8fKsTBRedVyaTrb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 18, 'total_tokens': 73, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = llm_with_binded_tools.invoke(\"What is the price of GOOGLE stock?\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195.47500610351562"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stock_price.invoke(out.tool_calls[0]['args'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End2End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a real-world scenario, we can use the tools to perform complex operations and feed the result to the model and model will responed with human friendly message considering tool result.  \n",
    "This can be accomplished manually, builtin-agents, chains and graphs. Graphs will be introduced in the next notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Very Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the toolset\n",
    "tools = [get_stock_price, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Nnz8xI40Abjd5pODW3UaMy7z', 'function': {'arguments': '{\"symbol\":\"GOOGL\"}', 'name': 'get_stock_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 58, 'total_tokens': 76, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-617b1158-0d02-4eff-8307-080c81351878-0', tool_calls=[{'name': 'get_stock_price', 'args': {'symbol': 'GOOGL'}, 'id': 'call_Nnz8xI40Abjd5pODW3UaMy7z', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 18, 'total_tokens': 76, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start conversation\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "messages = [HumanMessage(\"Hello, what is the last price of Google stock?\")]\n",
    "out = llm_with_binded_tools.invoke(messages)\n",
    "# add returned AI message to the conversation\n",
    "messages.append(out)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_stock_price',\n",
       " 'args': {'symbol': 'GOOGL'},\n",
       " 'id': 'call_Nnz8xI40Abjd5pODW3UaMy7z',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get call details\n",
    "tc = out.tool_calls[0]\n",
    "tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='195.47500610351562', name='get_stock_price', tool_call_id='call_Nnz8xI40Abjd5pODW3UaMy7z')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find relevant langchain wrapped tool and invoke it. tc can be passed as is so that it returns a ToolMessage object just as we need.\n",
    "# otherwise if you pass args, you'll just get the return value of the tool.\n",
    "tool_call_result = {tool.name: tool for tool in tools}[tc['name']].invoke(tc)\n",
    "tool_call_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello, what is the last price of Google stock?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Nnz8xI40Abjd5pODW3UaMy7z', 'function': {'arguments': '{\"symbol\":\"GOOGL\"}', 'name': 'get_stock_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 58, 'total_tokens': 76, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-617b1158-0d02-4eff-8307-080c81351878-0', tool_calls=[{'name': 'get_stock_price', 'args': {'symbol': 'GOOGL'}, 'id': 'call_Nnz8xI40Abjd5pODW3UaMy7z', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 18, 'total_tokens': 76, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='195.47500610351562', name='get_stock_price', tool_call_id='call_Nnz8xI40Abjd5pODW3UaMy7z')]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the tool result to the conversation and call LLM again\n",
    "messages.append(tool_call_result)\n",
    "messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The last price of Google stock (GOOGL) is $195.48.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 91, 'total_tokens': 110, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-75312e84-edca-45bf-889e-d583fe099e97-0', usage_metadata={'input_tokens': 91, 'output_tokens': 19, 'total_tokens': 110, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_binded_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Less Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes LLM model may need multiple calls to the tool to get the desired result. Suppose we ask stock price of multiple stocks.\n",
    "In the less manual way, we'll need to call the tool with batch and feed the result to the model and we'll do this with a ChatPromptTemplate that contains messages placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# we can define a template that can be used to contain both user input and other messages (AI, Tool)\n",
    "# messages variable can be empty for the first call and later it can be filled with AI and Tool messages.\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"human\", \"{user_input}\"),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a chain from template to LLM with tools\n",
    "templated_llm_with_binded_tools = prompt_template | llm_with_binded_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_stock_price',\n",
       "  'args': {'symbol': 'GOOGL'},\n",
       "  'id': 'call_yHuMIp49vAo0MFzXBl5Nq4WP',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'get_stock_price',\n",
       "  'args': {'symbol': 'AAPL'},\n",
       "  'id': 'call_etGicZPqRMlZt4vGeCFbS7kz',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"What is the price of GOOGLE and APPL stocks?\"\n",
    "ai_message = templated_llm_with_binded_tools.invoke(user_input)\n",
    "ai_message.tool_calls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, we have multiple tool_call requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolMessage(content='195.47500610351562', name='get_stock_price', tool_call_id='call_yHuMIp49vAo0MFzXBl5Nq4WP'),\n",
       " ToolMessage(content='238.91000366210938', name='get_stock_price', tool_call_id='call_etGicZPqRMlZt4vGeCFbS7kz')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_msgs = get_stock_price.batch(ai_message.tool_calls)\n",
    "tool_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The current price of Google (GOOGL) stock is approximately $195.48, and the price of Apple (AAPL) stock is approximately $238.91.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 135, 'total_tokens': 172, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-bf2d437f-148a-44db-b96b-261895e616f4-0', usage_metadata={'input_tokens': 135, 'output_tokens': 37, 'total_tokens': 172, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templated_llm_with_binded_tools.invoke({\"user_input\":user_input, \"messages\":[ai_message, *tool_msgs]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"), \n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_stock_price` with `{'symbol': 'GOOGL'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m195.4199981689453\u001b[0m\u001b[32;1m\u001b[1;3mThe current stock price of Google (GOOGL) is approximately $195.42.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's Google stock price\",\n",
       " 'output': 'The current stock price of Google (GOOGL) is approximately $195.42.'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt_template)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\":\"what's Google stock price\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using chaining with @chain decator, we can even simplify the scenario in `Less Manual` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "# again we'll use a template that can contain messages\n",
    "today = datetime.datetime.today().strftime(\"%D\")\n",
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"human\", \"{user_input}\"),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the chain to combine user input, ai messages and tool messages\n",
    "@chain\n",
    "def tool_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = templated_llm_with_binded_tools.invoke(input_, config=config)\n",
    "    tool_msgs = get_stock_price.batch(ai_msg.tool_calls, config=config)\n",
    "    return templated_llm_with_binded_tools.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The current stock prices are as follows:\\n- **GOOGLE (GOOGL)**: $195.42\\n- **Apple (AAPL)**: $238.90', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 135, 'total_tokens': 172, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'stop', 'logprobs': None}, id='run-cfeaa721-2c29-4180-8da8-d390c2ebb219-0', usage_metadata={'input_tokens': 135, 'output_tokens': 37, 'total_tokens': 172, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke the chain\n",
    "tool_chain.invoke(\"What is the price of GOOGLE and APPL stocks?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Builtin Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many builtin tools under langchain-community packpage. These tools can be used in the model call.   \n",
    "https://python.langchain.com/docs/integrations/tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The White House, official residence of the president of the United States, in July 2008. The president of the United States is the head of state and head of government of the United States, [1] indirectly elected to a four-year term via the Electoral College. [2] Under the U.S. Constitution, the officeholder leads the executive branch of the federal government and is the commander-in-chief of ... The child\\'s name is \"Barack Hussein Obama II\" and the purported document bears much of the same information as Obama\\'s authentic birth certificate from his birth at the Kapiolani Maternity ... Obama\\'s father, Barack Obama, Sr., was a teenage goatherd in rural Kenya, won a scholarship to study in the United States, and eventually became a senior economist in the Kenyan government.Obama\\'s mother, S. Ann Dunham, grew up in Kansas, Texas, and Washington state before her family settled in Honolulu.In 1960 she and Barack Sr. met in a Russian language class at the University of Hawaii ... Born on August 4, 1961, in Honolulu, Hawaii, Obama is the first president born outside the continental United States. His full name is Barack Hussein Obama II, named after his father. Obama\\'s mother, Ann Dunham, was from Kansas, while his father, Barack Obama Sr., hailed from Kenya. Path to Presidency. In 1992, Obama married Michelle Robinson and entered politics as a member of the Illinois Senate, setting the stage for his ultimate election to the United States Senate in 2004.'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "search.invoke({'query':\"Obama's first name?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### via Tool calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use tool calling feature of the models and bind a tool to get a structured output as arguments for the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ResponseFormatter(BaseModel):\n",
    "    \"\"\"Always use this tool to structure your response to the user.\"\"\"\n",
    "    sentiment: str = Field(description=\"Is the text is positive, neutral or negative. Only provide one of these words\")\n",
    "    subject: str = Field(description=\"What's the subject of text with one word\")\n",
    "    price: float = Field(description=\"Price of the product. Set to 0 if no price mentioned in the text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_binded_structuring_tools = llm.bind_tools([ResponseFormatter])\n",
    "# Invoke the model\n",
    "ai_msg = llm_with_binded_structuring_tools.invoke(\"Costed me 50$ but this headphone sounds nothing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ResponseFormatter',\n",
       " 'args': {'sentiment': 'negative', 'subject': 'headphone', 'price': 50},\n",
       " 'id': 'call_wDKmDqk2LL65evf18QSSDGIl',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseFormatter(sentiment='negative', subject='headphone', price=50.0)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross check the output by parsing dictionary into a pydantic object\n",
    "pydantic_object = ResponseFormatter.model_validate(ai_msg.tool_calls[0][\"args\"])\n",
    "pydantic_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### via JSON mode (model specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some models support json mode to generate json output specifically for structured outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_template(\"\"\"\n",
    "Return a JSON object with keys 'sentiment' and 'subject' for the user review about a purchased product:\n",
    "{review}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_with_json_output = ChatOpenAI(model=\"gpt-4o-mini\", model_kwargs={ \"response_format\": { \"type\": \"json_object\" } })\n",
    "templated_llm_with_json_output = template | llm_with_json_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg = templated_llm_with_json_output.invoke({\"review\":\"This headphone sounds great and I'd think of buying another pair.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'positive', 'subject': 'headphone'}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.loads(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### via langchain Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseFormatter(sentiment='positive', subject='headphone', price=0.0)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bind the schema to the model\n",
    "llm_with_structured_output = llm.with_structured_output(ResponseFormatter)\n",
    "\n",
    "templated_llm_with_structured_output = template | llm_with_structured_output\n",
    "\n",
    "# Invoke the model\n",
    "structured_output = templated_llm_with_structured_output.invoke({\"review\":\"This headphone sounds great and I'd think of buying another pair.\"})\n",
    "# Get back the pydantic object\n",
    "structured_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all LLMs may have structured output support. In such cases, we can utilize prompts, pydantic models, and tools to get structured outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from pydantic import BaseModel, Field, model_validator, field_validator\n",
    "from typing_extensions import Self\n",
    "\n",
    "\n",
    "# instantiate a model without structured output\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseFormatter(BaseModel):\n",
    "    \"\"\"Always use this tool to structure your response to the user.\"\"\"\n",
    "    sentiment: str = Field(description=\"Is the text is positive, neutral or negative. Only provide one of these words\")\n",
    "    subject: str = Field(description=\"What's the subject of text with one word\")\n",
    "    price: float = Field(description=\"Price of the product. Set to 0 if no price mentioned in the text\")\n",
    "    num_stars: int = Field(\"Possible rate value of review between 1-5 where 5 is the best\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydant for fields or model as a whole\n",
    "    # field, after example\n",
    "    @field_validator('num_stars', mode='after')  \n",
    "    @classmethod\n",
    "    def after_check_num_start(cls, value: int) -> int:\n",
    "        if not(1 <= value <= 5):\n",
    "            raise ValueError(\"Badly formed num of stars\")\n",
    "        return value\n",
    "\n",
    "    # model, before example\n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def before_check(cls, values: dict) -> dict:\n",
    "        # values contain sentinment, subject and price as a dictionary.\n",
    "        # run before the model is instantiated. These are more flexible than after validators, but they also have to deal with the raw input.\n",
    "        return values\n",
    "    \n",
    "    # model, after example\n",
    "    @model_validator(mode='after')\n",
    "    def after_check(self) -> Self:\n",
    "        # run after Pydantic's internal validation. They are generally more type safe and thus easier to implement.\n",
    "        if self.sentiment not in ['positive', 'neutral', 'negative']:\n",
    "            raise ValueError('sentiment error')\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Always use this tool to structure your response to the user.\", \"properties\": {\"sentiment\": {\"description\": \"Is the text is positive, neutral or negative. Only provide one of these words\", \"title\": \"Sentiment\", \"type\": \"string\"}, \"subject\": {\"description\": \"What's the subject of text with one word\", \"title\": \"Subject\", \"type\": \"string\"}, \"price\": {\"description\": \"Price of the product. Set to 0 if no price mentioned in the text\", \"title\": \"Price\", \"type\": \"number\"}, \"num_stars\": {\"default\": \"Possible rate value of review between 1-5 where 5 is the best\", \"title\": \"Num Stars\", \"type\": \"integer\"}}, \"required\": [\"sentiment\", \"subject\", \"price\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Set up a parser, observe the internal formatting instructions to be passed to LLM input. We'll invoke parser with the output of LLM.\n",
    "parser = PydanticOutputParser(pydantic_object=ResponseFormatter)\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['review'], input_types={}, partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Always use this tool to structure your response to the user.\", \"properties\": {\"sentiment\": {\"description\": \"Is the text is positive, neutral or negative. Only provide one of these words\", \"title\": \"Sentiment\", \"type\": \"string\"}, \"subject\": {\"description\": \"What\\'s the subject of text with one word\", \"title\": \"Subject\", \"type\": \"string\"}, \"price\": {\"description\": \"Price of the product. Set to 0 if no price mentioned in the text\", \"title\": \"Price\", \"type\": \"number\"}, \"num_stars\": {\"default\": \"Possible rate value of review between 1-5 where 5 is the best\", \"title\": \"Num Stars\", \"type\": \"integer\"}}, \"required\": [\"sentiment\", \"subject\", \"price\"]}\\n```'}, template='Evaluate the user review.\\n{format_instructions}\\n{review}\\n')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inject internal formatting instructions into the prompt template. \n",
    "template = PromptTemplate(\n",
    "    template=\"Evaluate the user review.\\n{format_instructions}\\n{review}\\n\",\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseFormatter(sentiment='positive', subject='headphone', price=0.0, num_stars=5)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "templated_llm = template | llm\n",
    "output = templated_llm.invoke(\"This headphone sounds great and I'd think of buying another pair.\")\n",
    "parser.invoke(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
